\subsection{Dynamic Time Warping Approach}
Η υλοποίησή μας βασίζεται σε μια παραλλαγή της μεθόδου του \emph{Dynamic Time Warping (DTW)}, το \emph{FastDTW} \cite{salvador2007toward},
όπου θυσιάζοντας ακρίβεια πετυχαίνουμε αλγοριθμική πολυπλοκότητα τάξης $\mathcal{O}(n)$, μια τάξη μεγέθους παρακάτω από από τον κλασσικό
αλγόριθμο DTW του οποίου η πολυπλοκότητα είναι τετραγωνική, δηλαδή $\mathcal{O}(n^2)$. Σύμφωνα με την εργασία \cite{salvador2007toward},
με τις κατάλληλες ρυθμίσεις στον αλγόριθμο \emph{FastDTW}, μπορούμε να πετύχουμε ένα καλό ισοζύγιο μεταξύ απώλειας ακρίβειας και
υπολογιστικής πολυπλοκότητας.

Επιλέξαμε να εργαστούμε σε \emph{Python} \cite{python}, καθώς υπάρχει πληθώρα διαθέσιμων βιβλιοθηκών όπως οι γενικής χρήσης επιστημονικές
\emph{NumPy} \cite{numpy} και \emph{SciPy} \cite{scipy}, ή οι πιο domain-specific \emph{aubio} \cite{aubio} και \emph{Music21}
\cite{music21} που προσφέρουν εργαλεία για επεξεργασία ήχου. Επιπλέον χρησιμοποιήθηκε η βιβλιοθήκη \emph{fastdtw} \cite{fastdtwpython}, που
προσφέρει μια υλοποίηση του ομώνυμου αλγορίθμου. Επιπλέον κάναμε την παραδοχή ότι όλα τα input queries, δηλαδή οι ηχογραφήσεις των
χρηστών, θα ξεκινάνε από την αρχή του τραγουδιού και όχι από κάποιο άλλο σημείο του. Για το λόγο αυτό εργαστήκαμε κυρίως στο dataset του
\emph{MIR-QbSH} του \emph{Roger Jang} \cite{jang-dataset}, το οποίο εγγυάται ότι όλες οι ηχογραφήσεις ανταποκρίνονται στην αρχή του
τραγουδιού σε αντίθεση με το \emph{IOACAS} dataset \cite{IOACAS-dataset}.

Υπενθυμίζουμε ότι το \emph{DTW} υπολογίζει το warping distance μεταξύ ακολουθιακών δεδομένων όπως μια χρονοσειρά, δηλαδή την χρονική και
χωρική παραμόρφωση που πρέπει να υποστεί η μία ακολουθία για να αντιστοιχίζεται στην άλλη. Τα ακολουθιακά δεδομένα μας είναι χρονοσειρές
με την τιμή του pitch για κάθε ένα frame του ήχου, οι οποίες λέγονται και pitch vectors (PVs). Χρειαζόμαστε τα PVs και των input queries
και των ground truth MIDI αρχείων, και θέλουμε να βρούμε την ομοιότητα μεταξύ τους. Να σημειωθεί ότι όλα τα ηχητικά μας σήματα έχουν
συχνότητα δειγματοληψίας $8 \mathrm{ kHz}$. Επιπλέον επιλέγουμε σταθερό μέγεθος frame στα $32 \mathrm{ ms}$, το οποίο είναι αρκούντως
μεγάλο ώστε να μπορούμε να εκτιμήσουμε τους περισσότερους τόνους ενός τραγουδιού. Έτσι παραδείγματος χάρη, ένα input query διάρκειας 8
δευτερολέπτων θα αποτελείται από 250 frames και θα αναπαριστάται από μια χρονοσειρά μήκους 250 στοιχείων, της οποίας οι τιμές θα είναι το
pitch για κάθε frame.

Η διαδικασία που ακολουθούμε είναι η εξής: αρχικά εξάγουμε τα PVs από τα αρχεία MIDI με τη χρήση της βιβλιοθήκης \emph{Music21}
\cite{music21} και τα αποθηκεύουμε σε μια απλοϊκή βάση δεδομένων. Έπειτα, θέλουμε να εξάγουμε τα PVs από τα WAVE αρχεία, αλλά επειδή εδώ η
πληροφορία του τόνου δεν περιλαμβάνεται μέσα στο ίδιο το αρχείο (όπως γίνεται με τα MIDI), καλούμαστε να χρησιμοποιήσουμε κάποιον pitch
tracking αλγόριθμο. Η βιβλιοθήκη \emph{aubio} \cite{aubio} προσφέρει διάφορες υλοποιήσεις pitch tracking αλγορίθμων, ένας εκ' των οποίων
είναι ο αλγόριθμος Yin \cite{de2002yin}, τον οποίο χρησιμοποιούμε. Καταλήξαμε σε αυτόν τον αλγόριθμό γιατί είδαμε ότι προσέφερε τα καλύτερα
αποτελέσματα για το δοσμένο dataset, καθώς τα εξαγόμενα PVs έμοιαζαν αρκετά σε αυτά που δινόταν από το corpus. Εφόσον έχουμε εξάγει τα PVs
και από τα WAVE αρχεία τα τοποθετούμε και αυτά σε μια απλοϊκή βάση δεδομένων. Για κάθε ένα input query που έχουμε στη βάση, το
προεπεξαργαζόμαστε και το βρίσκουμε την DTW απόστασή του από κάθε PV της βάσης των ground truths. Τα pitches είναι σε MIDI scale, και όταν
ο tracker αδυνατεί να βρει το dominant frequency με επαρκές confidence, τότε θεωρούμε ότι έχουμε ησυχία στο τρέχον frame και θέτουμε το
pitch του 0.

Αρχικά η διαδικασία της προεπεξεργασίας εμπνεύστηκε από την εργασία \cite{Zhu:2003:WIE:872757.872780}, όπου η κάθε χρονοσειρά μετατρεπόταν
στην κανονική της μορφή \cite{goldin1995similarity}, δηλαδή φέρναμε το μέσο όρο των τιμών στο 0 και τη διασπορά στη μονάδα. Όμως επειδή το
pitch δεν είναι σε γραμμική κλίμακα, ένας τέτοιος μετασχηματισμός μπορεί να οδηγούσε σε παραμόρφωση της πληροφορίας. Επιπλέον, αφαιρούσαμε
τελείως τα "ήσυχα" frames, δηλαδή αυτά που είχαν μηδενικό pitch value, πράγμα το οποίο επίσης αφαιρεί πληροφορία. Η προσέγγιση αυτή
οδηγούσε σε κατώτερα του μετρίου αποτελέσματα και χρειάστηκε να αναθεωρηθεί. Έτσι, ακολουθήσαμε μια διαδικασία παρόμοια με αυτήν που
προτείνεται στην εργασία \cite{stasiak2014follow} η οποία επέφερε καλύτερα αποτελέσματα. Καταρχάς, πλέον δεν κανονικοποιούμε κανένα PV,
και οποιαδήποτε προεπεξεργασία συμβαίνει μόνο στο input query, αφήνοντας το ground truth ανεπηρέαστο. Αρχικά λοιπόν, αφαιρούμε τα frames
με μηδενικό pitch που βρίσκονται μόνο στην αρχή και στο τέλος του query. Έπειτα, βρίσκουμε τη μέση τιμή της χρονοσειράς, θεωρούμε ένα όριο
$T_1$, και όσα frames έχουν pitch που απέχει πάνω από $\pm T_1$ ημιτόνια από το μέσο, τα θεωρούμε "ήσυχα" (μηδενίζουμε το pitch value
τους). Επιπλέον, αν μεταξύ δύο διαδοχικών frames παρατηρήσουμε διαφορά στα pitch values πάνω από $T_2$ ημιτόνια, τότε θέτουμε το pitch του
δεύτερου frame να ισούται με
$$p_2 = p_1 + \mathrm{sgn}(\Delta p) T_2$$
όπου $p_1, p_2$ το pitch value του πρώτου και δεύτερου frame αντίστοιχα και $\Delta p$ η μεταξύ τους διαφορά. Έπειτα, κάθε frame με
μηδενικό pitch value του αναθέτουμε το pitch value του προηγούμενου μη-μηδενικού frame, ώστε να μην έχουμε στιγμές ησυχίας μέσα στο query
μας. Άλλωστε, τα MIDI αρχεία που έχουμε δεν έχουνε παύσεις μέσα τους, οπότε δεν μας ωφελούν ιδιαίτερα οι παύσεις στα input queries.
Τέλος, εξομαλύνουμε τη χρονοσειρά με ένα $\mathrm{MA}(9)$ φίλτρο. Επίσης πριν βρούμε την \emph{DTW} απόσταση μεταξύ ενός διανύσματος
$\vec{q}$ και του ground truth $\vec{t}$, βρίσκουμε τη διαφορά των μέσων όρων τους
$$d = \mathbb{E}[\vec{q}] - \mathbb{E}[\vec{t}]$$
και την αφαιρούμε από το input query $\vec{q}$, υπολογίζοντας έτσι την απόσταση $D^2_{DTW}(\vec{q} - d, \vec{t})$. Αυτό το
κάνουμε για να εξαλείψουμε οποιαδήποτε διαφορά έχουμε στο απόλυτο pitch, μιας και μας ενδιαφέρουν κυρίως οι σχετικές μεταβολές.