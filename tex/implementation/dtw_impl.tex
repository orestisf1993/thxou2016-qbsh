\subsection{Υλοποίηση με Dynamic Time Warping}
Όπως έχουμε αναφέρει και παραπάνω το πρόβλημα του Query by Singing/Humming μπορεί να χωριστεί σε 
τρία επιμέρους προβλήματα. Συνεπώς η παρουσίαση της υλοποίησης θα χωριστεί και αυτή σε τρία υποκεφάλαια.
Επιλέξαμε να εργαστούμε σε \emph{Python} \cite{python}, επειδή είναι μια πολύ καλή γλώσσα προγραμματισμού για επιστημονικές εφαρμογές καθώς υπάρχει πληθώρα διαθέσιμων βιβλιοθηκών όπως οι γενικής χρήσης επιστημονικές
\emph{NumPy} \cite{numpy} και \emph{SciPy} \cite{scipy}, ή οι πιο domain-specific \emph{aubio} \cite{aubio} και \emph{Music21}
\cite{music21} που προσφέρουν εργαλεία για επεξεργασία ήχου. Επίσης, είναι μια καλή επιλογή για project που γίνεται στα πλαίσια ενός μαθήματος καθώς μας δίνει τη δυνατότητα να φτιάξουμε γρήγορα ένα πρωτότυπο της εφαρμογής που θέλουμε να υλοποιήσουμε.

\subsubsection{Δημιουργία των Βάσεων Δεδομένων με τις μελωδίες}
Η διαδικασία που ακολουθούμε είναι η εξής: αρχικά εξάγουμε τα pitch vectors από τα αρχεία MIDI με τη χρήση της βιβλιοθήκης \emph{Music21}
\cite{music21} και τα αποθηκεύουμε σε μια απλοϊκή βάση δεδομένων. Έπειτα, θέλουμε να εξάγουμε τα pitch vectors από τα WAVE αρχεία, αλλά επειδή εδώ η
πληροφορία του τόνου δεν περιλαμβάνεται μέσα στο ίδιο το αρχείο (όπως γίνεται με τα MIDI), καλούμαστε να χρησιμοποιήσουμε κάποιον pitch
tracking αλγόριθμο. Η βιβλιοθήκη \emph{aubio} \cite{aubio} προσφέρει διάφορες υλοποιήσεις pitch tracking αλγορίθμων, ένας εκ' των οποίων
είναι ο αλγόριθμος Yin \cite{de2002yin}, τον οποίο χρησιμοποιούμε. Καταλήξαμε σε αυτόν τον αλγόριθμό γιατί είδαμε ότι προσέφερε τα καλύτερα
αποτελέσματα για το δοσμένο dataset, καθώς τα εξαγόμενα pitch vectors έμοιαζαν αρκετά με αυτά που δινόταν από το corpus. Εφόσον έχουμε εξάγει τα pitch vectors
και από τα WAVE αρχεία τα τοποθετούμε και αυτά σε μια απλοϊκή βάση δεδομένων. Για κάθε ένα input query που έχουμε στη βάση, το
προεπεξαργαζόμαστε και το βρίσκουμε την DTW απόστασή του από κάθε pitch vector της βάσης των ground truths. Τα pitches είναι σε MIDI scale, και όταν
ο tracker αδυνατεί να βρει το dominant frequency με επαρκές confidence, τότε θεωρούμε ότι έχουμε ησυχία στο τρέχον frame και θέτουμε το
pitch του 0.

\subsubsection{Προεπεξεργασία των Pitch Vectors}
Αρχικά η διαδικασία της προεπεξεργασίας των pitch vectors εμπνεύστηκε από την εργασία \cite{Zhu:2003:WIE:872757.872780}, όπου η κάθε χρονοσειρά μετατρεπόταν
στην κανονική της μορφή \cite{goldin1995similarity}, δηλαδή φέρναμε το μέσο όρο των τιμών στο 0 και τη διασπορά στη μονάδα. Όμως επειδή το
pitch δεν είναι σε γραμμική κλίμακα, ένας τέτοιος μετασχηματισμός μπορεί να οδηγούσε σε παραμόρφωση της πληροφορίας. Επιπλέον, αφαιρούσαμε
τελείως τα "ήσυχα" frames, δηλαδή αυτά που είχαν μηδενικό pitch value, πράγμα το οποίο επίσης αφαιρεί πληροφορία. Η προσέγγιση αυτή
οδηγούσε σε κατώτερα του μετρίου αποτελέσματα και χρειάστηκε να αναθεωρηθεί. Έτσι, ακολουθήσαμε μια διαδικασία παρόμοια με αυτήν που
προτείνεται στην εργασία \cite{stasiak2014follow} η οποία επέφερε καλύτερα αποτελέσματα. Καταρχάς, πλέον δεν κανονικοποιούμε κανένα pitch vector,
και οποιαδήποτε προεπεξεργασία συμβαίνει \textbf{μόνο στο input query}, αφήνοντας το ground truth ανεπηρέαστο. Αρχικά λοιπόν, αφαιρούμε τα frames
με μηδενικό pitch που βρίσκονται μόνο στην αρχή και στο τέλος του query. Έπειτα, βρίσκουμε τη μέση τιμή της χρονοσειράς, θεωρούμε ένα όριο
$T_1$, και όσα frames έχουν pitch που απέχει πάνω από $\pm T_1$ ημιτόνια από το μέσο, τα θεωρούμε "ήσυχα" (μηδενίζουμε το pitch value
τους). Επιπλέον, αν μεταξύ δύο διαδοχικών frames παρατηρήσουμε διαφορά στα pitch values πάνω από $T_2$ ημιτόνια, τότε θέτουμε το pitch του
δεύτερου frame να ισούται με
$$p_2 = p_1 + \mathrm{sgn}(\Delta p) T_2$$
όπου $p_1, p_2$ το pitch value του πρώτου και δεύτερου frame αντίστοιχα και $\Delta p$ η μεταξύ τους διαφορά. Έπειτα, κάθε frame με
μηδενικό pitch value του αναθέτουμε το pitch value του προηγούμενου μη-μηδενικού frame, ώστε να μην έχουμε στιγμές ησυχίας μέσα στο query
μας. Άλλωστε, τα MIDI αρχεία που έχουμε δεν έχουνε παύσεις μέσα τους, οπότε δεν μας ωφελούν ιδιαίτερα οι παύσεις στα input queries.
Τέλος, εξομαλύνουμε τη χρονοσειρά με ένα $\mathrm{MA}(9)$ φίλτρο ή με Median Filter ενάτου βαθμού. Επίσης πριν βρούμε την \emph{DTW} απόσταση μεταξύ ενός διανύσματος
$\vec{q}$ και του ground truth $\vec{t}$, βρίσκουμε τη διαφορά των μέσων όρων τους
$$d = \mathbb{E}[\vec{q}] - \mathbb{E}[\vec{t}]$$
και την αφαιρούμε από το input query $\vec{q}$, υπολογίζοντας έτσι την απόσταση $D^2_{DTW}(\vec{q} - d, \vec{t})$. Αυτό το
κάνουμε για να εξαλείψουμε οποιαδήποτε διαφορά έχουμε στο απόλυτο pitch, μιας και μας ενδιαφέρουν κυρίως οι σχετικές μεταβολές.

\subsubsection{Αντιστοίχιση Μελωδιών}

Η υλοποίησή μας βασίζεται σε μια παραλλαγή της μεθόδου του \emph{Dynamic Time Warping (DTW)}, το \emph{FastDTW} \cite{salvador2007toward},
όπου θυσιάζοντας ακρίβεια πετυχαίνουμε αλγοριθμική πολυπλοκότητα τάξης $\mathcal{O}(n)$, μια τάξη μεγέθους παρακάτω από από τον κλασσικό
αλγόριθμο DTW του οποίου η πολυπλοκότητα είναι τετραγωνική, δηλαδή $\mathcal{O}(n^2)$. Σύμφωνα με την εργασία \cite{salvador2007toward},
με τις κατάλληλες ρυθμίσεις στον αλγόριθμο \emph{FastDTW}, μπορούμε να πετύχουμε ένα καλό ισοζύγιο μεταξύ απώλειας ακρίβειας και
υπολογιστικής πολυπλοκότητας. Πιο συγκεκριμένα όσο αυξάνουμε την ακτίνα του FastDTW πετυχαίνουμε καλύτερη ακρίβεια προσεγγίζοντας τη λειτουργία του συμβατικού DTW, ταυτόχρονα όμως αυξάνεται και ο χρόνος εκτέλεσης του αλγορίθμου. Για την υλοποίηση του FastDTW χρησιμοποιήσαμε την βιβλιοθήκη \emph{fastdtw} για Python \cite{fastdtwpython}

Επιπλέον κάναμε την παραδοχή ότι όλα τα input queries, δηλαδή οι ηχογραφήσεις των
χρηστών, θα ξεκινάνε από την αρχή του τραγουδιού και όχι από κάποιο άλλο σημείο του. Για το λόγο αυτό εργαστήκαμε κυρίως στο dataset του
\emph{MIR-QbSH} του \emph{Roger Jang} \cite{jang-dataset}, το οποίο εγγυάται ότι όλες οι ηχογραφήσεις ανταποκρίνονται στην αρχή του
τραγουδιού σε αντίθεση με το \emph{IOACAS} dataset \cite{IOACAS-dataset}. Αυτή η παραδοχή έγινε ώστε να 
μπορούμε να κόβουμε τα ground truth MIDI αρχεία και να κερδίζουμε χρόνο κατά την εκτέλεση του αλγορίθμου. Πιο 
συγκεκριμένα κόβοντας τα MIDI αρχεία τα οποία έχουν περίπου μέγεθος 30s, το οποίο αντιστοιχεί σε pitch vector 
μεγέθους 937 στοιχείων, καταλήγουμε σε pitch vectors 250 στοιχείων. Έτσι πετυχαίνουμε αρκετά μεγάλη επιτάχυνση 
κατά την εκτέλεση της αντιστοίχισης. 

Υπενθυμίζουμε ότι το \emph{DTW} υπολογίζει το warping distance μεταξύ ακολουθιακών δεδομένων όπως μια χρονοσειρά, δηλαδή την χρονική και
χωρική παραμόρφωση που πρέπει να υποστεί η μία ακολουθία για να αντιστοιχίζεται στην άλλη. Τα ακολουθιακά δεδομένα μας είναι χρονοσειρές
με την τιμή του pitch για κάθε ένα frame του ήχου, οι οποίες λέγονται και pitch vectors. Χρειαζόμαστε τα pitch vectors και των input queries
και των ground truth MIDI αρχείων, και θέλουμε να βρούμε την ομοιότητα μεταξύ τους. Να σημειωθεί ότι όλα τα ηχητικά μας σήματα έχουν
συχνότητα δειγματοληψίας $8 \mathrm{ kHz}$. Επιπλέον επιλέγουμε σταθερό μέγεθος frame στα $32 \mathrm{ ms}$, το οποίο είναι αρκούντως
μεγάλο ώστε να μπορούμε να εκτιμήσουμε τους περισσότερους τόνους ενός τραγουδιού. Έτσι παραδείγματος χάρη, ένα input query διάρκειας 8
δευτερολέπτων θα αποτελείται από 250 frames και θα αναπαριστάται από μια χρονοσειρά μήκους 250 στοιχείων, της οποίας οι τιμές θα είναι το
pitch για κάθε frame.
